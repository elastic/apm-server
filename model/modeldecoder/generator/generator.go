// Licensed to Elasticsearch B.V. under one or more contributor
// license agreements. See the NOTICE file distributed with
// this work for additional information regarding copyright
// ownership. Elasticsearch B.V. licenses this file to you under
// the Apache License, Version 2.0 (the "License"); you may
// not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

package generator

import (
	"bytes"
	"errors"
	"fmt"
	"go/ast"
	"go/token"
	"go/types"
	"path"
	"path/filepath"
	"reflect"
	"sort"
	"strings"

	"golang.org/x/tools/go/packages"
)

// Generator creates following struct methods
//   `IsSet() bool`
//   `Reset()`
//   `validate() error`
// on all structs (exported and unexported) that are referenced
// by at least one of the root types
type Generator struct {
	buf      bytes.Buffer
	pkgName  string
	rootObjs map[string]structType
	// parsed structs from loading types from the provided package
	structTypes structTypes
	// keep track of already processed types in case one type is
	// referenced multiple times
	processedTypes map[string]struct{}

	nullableString, nullableInt, nullableInterface string
}

// NewGenerator takes an importPath and the package name for which
// the type definitions should be loaded.
// The typPkg is used to implement validation rules specific to types
// of the package. The generator creates methods only for types referenced
// directly or indirectly by any of the root types.
func NewGenerator(importPath string, pkg string, typPath string,
	root []string) (*Generator, error) {
	loaded, err := loadPackage(path.Join(importPath, pkg))
	if err != nil {
		return nil, err
	}
	structTypes, err := parseStructTypes(loaded)
	if err != nil {
		return nil, err
	}
	g := Generator{
		pkgName:           loaded.Types.Name(),
		structTypes:       structTypes,
		rootObjs:          make(map[string]structType, len(root)),
		processedTypes:    make(map[string]struct{}),
		nullableString:    fmt.Sprintf("%s.String", typPath),
		nullableInt:       fmt.Sprintf("%s.Int", typPath),
		nullableInterface: fmt.Sprintf("%s.Interface", typPath),
	}
	for _, r := range root {
		rootObjPath := fmt.Sprintf("%s.%s", filepath.Join(importPath, pkg), r)
		rootObj, ok := structTypes[rootObjPath]
		if !ok {
			return nil, fmt.Errorf("object with root key %s not found", rootObjPath)
		}
		g.rootObjs[rootObj.name] = rootObj
	}
	return &g, nil
}

// Generate writes generated methods to the buffer
func (g *Generator) Generate() (bytes.Buffer, error) {
	fmt.Fprintf(&g.buf, `
// Code generated by "modeldecoder/generator". DO NOT EDIT.

package %s

import (
	"encoding/json"
	"fmt"
	"unicode/utf8"
)
`[1:], g.pkgName)

	for _, rootObj := range g.rootObjs {
		if err := g.generate(rootObj, ""); err != nil {
			return g.buf, err
		}
	}
	return g.buf, nil
}

const (
	ruleRequired    = "required"
	ruleMax         = "max"
	ruleMaxVals     = "maxVals"
	rulePattern     = "pattern"
	rulePatternKeys = "patternKeys"
	ruleTypes       = "types"
	ruleTypesVals   = "typesVals"
)

type structTypes map[string]structType

type structType struct {
	name   string
	fields []structField
}
type structField struct {
	name string
	typ  types.Type
	tag  reflect.StructTag
}

// create flattened field keys by recursively iterating through the struct types;
// there is only struct local knowledge and no knowledge about the parent,
// deriving the absolute key is not possible in scenarios where one struct
// type is referenced as a field in multiple struct types
func (g *Generator) generate(st structType, key string) error {
	if _, ok := g.processedTypes[st.name]; ok {
		return nil
	}
	g.processedTypes[st.name] = struct{}{}
	if err := g.generateIsSet(st, key); err != nil {
		return err
	}
	if err := g.generateReset(st, key); err != nil {
		return err
	}
	if err := g.generateValidation(st, key); err != nil {
		return err
	}
	if key != "" {
		key += "."
	}
	for _, f := range st.fields {
		if child, ok := g.structTypes[f.typ.String()]; ok {
			if err := g.generate(child, fmt.Sprintf("%s%s", key, jsonName(f))); err != nil {
				return err
			}
		}
	}
	return nil
}

func (g *Generator) generateIsSet(structTyp structType, key string) error {
	fmt.Fprintf(&g.buf, `
func (m *%s) IsSet() bool {
	return`, structTyp.name)
	if key != "" {
		key += "."
	}
	for i := 0; i < len(structTyp.fields); i++ {
		prefix := ` ||`
		if i == 0 {
			prefix = ``
		}
		f := structTyp.fields[i]

		switch t := f.typ.Underlying().(type) {
		case *types.Slice, *types.Map:
			fmt.Fprintf(&g.buf, `%s len(m.%s) > 0`, prefix, f.name)
		case *types.Struct:
			fmt.Fprintf(&g.buf, `%s m.%s.IsSet()`, prefix, f.name)
		default:
			return fmt.Errorf("unhandled type %T for IsSet() for '%s%s'", t, key, jsonName(f))
		}
	}
	fmt.Fprint(&g.buf, `
}
`)
	return nil
}

func (g *Generator) generateReset(structTyp structType, key string) error {
	fmt.Fprintf(&g.buf, `
func (m *%s) Reset() {
`, structTyp.name)
	if key != "" {
		key += "."
	}
	for _, f := range structTyp.fields {
		switch t := f.typ.Underlying().(type) {
		case *types.Slice:
			// the slice len is set to zero, not returning the underlying
			// memory to the garbage collector; when the size of slices differs
			// this potentially leads to keeping more memory allocated than required;
			// at the moment metadata.process.argv is the only slice
			fmt.Fprintf(&g.buf, `
m.%s = m.%s[:0]
`[1:], f.name, f.name)
		case *types.Map:
			// the map is cleared, not returning the underlying memory to
			// the garbage collector; when map size differs this potentially
			// leads to keeping more memory allocated than required
			fmt.Fprintf(&g.buf, `
for k := range m.%s {
	delete(m.%s, k)
}
`[1:], f.name, f.name)
		case *types.Struct:
			fmt.Fprintf(&g.buf, `
m.%s.Reset()
`[1:], f.name)
		default:
			return fmt.Errorf("unhandled type %T for Reset() for '%s%s'", t, key, jsonName(f))
		}
	}
	fmt.Fprint(&g.buf, `
}
`[1:])
	return nil
}

func (g *Generator) generateValidation(structTyp structType, key string) error {
	fmt.Fprintf(&g.buf, `
func (m *%s) validate() error {
`, structTyp.name)
	if _, ok := g.rootObjs[structTyp.name]; !ok {
		fmt.Fprint(&g.buf, `
if !m.IsSet() {
	return nil
}
`[1:])
	}

	if key != "" {
		key += "."
	}
	for i := 0; i < len(structTyp.fields); i++ {
		f := structTyp.fields[i]
		flattenedName := fmt.Sprintf("%s%s", key, jsonName(f))

		// if field is a model struct, call its validation function
		if _, ok := g.structTypes[f.typ.String()]; ok {
			fmt.Fprintf(&g.buf, `
if err := m.%s.validate(); err != nil{
	return err
}
`[1:], f.name)
		}

		parts, err := validationTag(f.tag)
		if err != nil {
			return fmt.Errorf("'%s': %w", flattenedName, err)
		}
		// use a sorted slice of tag keys to create tag related
		// validation methods in the same output order on every run
		var sortedRules = make([]string, 0, len(parts))
		for k := range parts {
			sortedRules = append(sortedRules, k)
		}
		sort.Slice(sortedRules, func(i, j int) bool {
			return sortedRules[i] < sortedRules[j]
		})

		switch t := f.typ.Underlying().(type) {
		case *types.Slice:
			for _, rule := range sortedRules {
				switch rule {
				case ruleRequired:
					fmt.Fprintf(&g.buf, `
if len(m.%s) == 0{
	return fmt.Errorf("'%s' required")
}
`[1:], f.name, flattenedName)
				default:
					return fmt.Errorf("unhandled tag rule '%s' for '%s'", rule, flattenedName)
				}
			}
		case *types.Map:
			var required bool
			if _, ok := parts[ruleRequired]; ok {
				required = true
				delete(parts, ruleRequired)
				fmt.Fprintf(&g.buf, `
if len(m.%s) == 0{
	return fmt.Errorf("'%s' required")
}
`[1:], f.name, flattenedName)
			}
			if len(parts) == 0 {
				continue
			}
			// iterate over map once and run checks
			fmt.Fprintf(&g.buf, `
for k,v := range m.%s{
`[1:], f.name)
			if regex, ok := parts[rulePatternKeys]; ok {
				delete(parts, rulePatternKeys)
				fmt.Fprintf(&g.buf, `
if !%s.MatchString(k){
	return fmt.Errorf("validation rule '%s(%s)' violated for '%s'")
}
`[1:], regex, rulePatternKeys, regex, flattenedName)
			}
			if types, ok := parts[ruleTypesVals]; ok {
				delete(parts, ruleTypesVals)
				fmt.Fprintf(&g.buf, `
switch t := v.(type){
`[1:])
				if !required {
					fmt.Fprintf(&g.buf, `
case nil:
`[1:])
				}
				for _, typ := range strings.Split(types, ";") {
					if typ == "number" {
						typ = "json.Number"
					}
					fmt.Fprintf(&g.buf, `
case %s:
`[1:], typ)
					if typ == "string" {
						if maxVal, ok := parts[ruleMaxVals]; ok {
							delete(parts, ruleMaxVals)
							fmt.Fprintf(&g.buf, `
if utf8.RuneCountInString(t) > %s{
	return fmt.Errorf("validation rule '%s(%s)' violated for '%s'")
}
`[1:], maxVal, ruleMaxVals, maxVal, flattenedName)
						}
					}
				}
				fmt.Fprintf(&g.buf, `
default:
	return fmt.Errorf("validation rule '%s(%s)' violated for '%s' for key %%s",k)
}
`[1:], ruleTypesVals, types, flattenedName)
			}
			// close iteration over map
			fmt.Fprintf(&g.buf, `
}
`[1:])
			if len(parts) > 0 {
				return fmt.Errorf("unhandled tag rule(s) '%v' for '%s'", parts, flattenedName)
			}
		case *types.Struct:
			switch f.typ.String() {
			//TODO(simitt): can these type checks be more generic?
			case g.nullableString:
				for _, rule := range sortedRules {
					val := parts[rule]
					switch rule {
					case ruleRequired:
						fmt.Fprintf(&g.buf, `
if !m.%s.IsSet()  {
	return fmt.Errorf("'%s' required")
}
`[1:], f.name, flattenedName)
					case ruleMax:
						fmt.Fprintf(&g.buf, `
if utf8.RuneCountInString(m.%s.Val) > %s{
return fmt.Errorf("validation rule '%s(%s)' violated for '%s'")
}
`[1:], f.name, val, rule, val, flattenedName)
					case rulePattern:
						fmt.Fprintf(&g.buf, `
if !%s.MatchString(m.%s.Val){
	return fmt.Errorf("validation rule '%s(%s)' violated for '%s'")
}
`[1:], val, f.name, rule, val, flattenedName)
					default:
						return fmt.Errorf("unhandled tag rule '%s' for '%s'", rule, flattenedName)
					}
				}
			case g.nullableInt:
				for _, rule := range sortedRules {
					val := parts[rule]
					switch rule {
					case ruleRequired:
						fmt.Fprintf(&g.buf, `
if !m.%s.IsSet() {
	return fmt.Errorf("'%s' required")
}
`[1:], f.name, flattenedName)
					case ruleMax:
						fmt.Fprintf(&g.buf, `
if m.%s.Val > %s{
	return fmt.Errorf("validation rule '%s(%s)' violated for '%s'")
}
`[1:], f.name, val, rule, val, flattenedName)
					default:
						return fmt.Errorf("unhandled tag rule '%s' for '%s'", rule, flattenedName)
					}
				}
			case g.nullableInterface:
				var required bool
				if _, ok := parts[ruleRequired]; ok {
					required = true
				}
				for _, rule := range sortedRules {
					val := parts[rule]
					switch rule {
					case ruleRequired:
						fmt.Fprintf(&g.buf, `
if !m.%s.IsSet() {
	return fmt.Errorf("'%s' required")
}
`[1:], f.name, flattenedName)
					case ruleMax:
						//handled in switch statement for string types
					case ruleTypes:
						fmt.Fprintf(&g.buf, `
switch t := m.%s.Val.(type){
`[1:], f.name)
						for _, typ := range strings.Split(val, ";") {
							if typ == "int" {
								fmt.Fprintf(&g.buf, `
case json.Number:
`[1:])
								fmt.Fprintf(&g.buf, `
if _, err := t.Int64(); err != nil{
	return fmt.Errorf("validation rule '%s(%s)' violated for '%s'")
}
`[1:], rule, val, flattenedName)
							}
							fmt.Fprintf(&g.buf, `
case %s:
`[1:], typ)
							if typ == "string" {
								if max, ok := parts[ruleMax]; ok {
									fmt.Fprintf(&g.buf, `
if utf8.RuneCountInString(t) > %s{
	return fmt.Errorf("validation rule '%s(%s)' violated for '%s'")
}
`[1:], max, ruleMax, max, flattenedName)
								}
							}
						}
						if !required {
							fmt.Fprintf(&g.buf, `
case nil:
`[1:])
						}
						fmt.Fprintf(&g.buf, `
default:
	return fmt.Errorf("validation rule '%s(%s)' violated for '%s'")
}
`[1:], rule, val, flattenedName)
					default:
						return fmt.Errorf("unhandled tag rule '%s' for '%s'", rule, flattenedName)
					}
				}
			default:
				for _, rule := range sortedRules {
					switch rule {
					case ruleRequired:
						fmt.Fprintf(&g.buf, `
if !m.%s.IsSet(){
	return fmt.Errorf("'%s' required")
}
`[1:], f.name, flattenedName)
					default:
						return fmt.Errorf("unhandled tag rule '%s' for '%s'", rule, flattenedName)
					}
				}
			}
		default:
			return fmt.Errorf("unhandled type %T for '%s'", t, flattenedName)
		}
	}
	fmt.Fprint(&g.buf, `
	return nil
}
`[1:])
	return nil
}

func jsonName(f structField) string {
	parts := parseTag(f.tag, "json")
	if len(parts) == 0 {
		return strings.ToLower(f.name)
	}
	return parts[0]
}

func loadPackage(pkg string) (*packages.Package, error) {
	cfg := packages.Config{
		Mode: packages.NeedTypes | packages.NeedSyntax | packages.NeedTypesInfo}
	pkgs, err := packages.Load(&cfg, pkg)
	if err != nil {
		return nil, err
	}
	if packages.PrintErrors(pkgs) > 0 {
		return nil, errors.New("packages load error")
	}
	return pkgs[0], nil
}

func parseStructTypes(pkg *packages.Package) (structTypes, error) {
	structs := make(structTypes)
	for _, syntax := range pkg.Syntax {
		for _, decl := range syntax.Decls {
			genDecl, ok := decl.(*ast.GenDecl)
			if !ok || genDecl.Tok != token.TYPE {
				continue
			}
			for _, spec := range genDecl.Specs {
				typeSpec, ok := spec.(*ast.TypeSpec)
				if !ok {
					continue
				}
				obj := pkg.TypesInfo.Defs[typeSpec.Name]
				if obj == nil {
					continue
				}
				named := obj.(*types.TypeName).Type().(*types.Named)
				typesStruct, ok := named.Underlying().(*types.Struct)
				if !ok {
					return nil, fmt.Errorf("unhandled type %T", named.Underlying())
				}
				numFields := typesStruct.NumFields()
				structFields := make([]structField, 0, numFields)
				for i := 0; i < numFields; i++ {
					f := typesStruct.Field(i)
					if !f.Exported() {
						continue
					}
					structFields = append(structFields, structField{
						name: f.Name(),
						typ:  f.Type(),
						tag:  reflect.StructTag(typesStruct.Tag(i)),
					})
				}
				structs[obj.Type().String()] = structType{name: obj.Name(), fields: structFields}
			}
		}
	}
	return structs, nil
}

func parseTag(structTag reflect.StructTag, tagName string) []string {
	tag, ok := structTag.Lookup(tagName)
	if !ok || tag == "-" {
		return nil
	}
	return strings.Split(tag, ",")
}

func validationTag(structTag reflect.StructTag) (map[string]string, error) {
	parts := parseTag(structTag, "validate")
	m := make(map[string]string, len(parts))
	for _, rule := range parts {
		parts := strings.Split(rule, "=")
		switch len(parts) {
		case 1:
			// valueless rule e.g. required
			if rule != parts[0] {
				return nil, fmt.Errorf("malformed tag '%s'", rule)
			}
			switch rule {
			case ruleRequired:
				m[rule] = ""
			default:
				return nil, fmt.Errorf("unhandled tag rule '%s'", rule)
			}
		case 2:
			// rule=value
			m[parts[0]] = parts[1]
			switch parts[0] {
			case ruleMax, ruleMaxVals, rulePattern, rulePatternKeys, ruleTypes, ruleTypesVals:
			default:
				return nil, fmt.Errorf("unhandled tag rule '%s'", parts[0])
			}
		default:
			return nil, fmt.Errorf("malformed tag '%s'", rule)
		}
	}
	return m, nil
}
