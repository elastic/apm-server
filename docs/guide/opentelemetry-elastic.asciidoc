[[open-telemetry-elastic]]
=== OpenTelemetry integration

:ot-spec:       https://github.com/open-telemetry/opentelemetry-specification/blob/master/README.md
:ot-contrib:    https://github.com/open-telemetry/opentelemetry-collector-contrib
:ot-repo:       https://github.com/open-telemetry/opentelemetry-collector
:ot-pipelines:  https://opentelemetry.io/docs/collector/configuration/#service
:ot-extension:  {ot-repo}/blob/master/extension/README.md
:ot-scaling:    {ot-repo}/blob/master/docs/performance.md

:ot-collector:  https://opentelemetry.io/docs/collector/getting-started/
:ot-dockerhub:  https://hub.docker.com/r/otel/opentelemetry-collector-contrib

https://opentelemetry.io/docs/concepts/what-is-opentelemetry/[OpenTelemetry] is a set
of APIs, SDKs, tooling, and integrations that enable the capture and management of
telemetry data from your services for greater observability. For more information about the
OpenTelemetry project, see the {ot-spec}[spec].

Elastic OpenTelemetry integrations allow you to reuse your existing OpenTelemetry
instrumentation to quickly analyze distributed traces and metrics to help you monitor
business KPIs and technical components with the {stack}.

There are two Elastic OpenTelemetry integrations available:

* <<open-telemetry-elastic-protocol,APM Server native support of OpenTelemetry protocol>> (recommended)
* <<open-telemetry-elastic-exporter,Elastic exporter on the OpenTelemetry collector>>

[[open-telemetry-elastic-protocol]]
==== APM Server native support of OpenTelemetry protocol

Elastic APM Server natively supports the OpenTelemetry protocol.
This means trace data and metrics collected from your applications and infrastructure can
be sent directly to APM Server using the OpenTelemetry protocol.

image::images/open-telemetry-protocol-arch.png[OpenTelemetry Elastic protocol architecture diagram]

[float]
[[instrument-apps-apm-server]]
===== Instrument applications

To export traces and metrics to APM Server, ensure that you have instrumented your services and applications
with the OpenTelemetry API, SDK, or both. For example, if you are a Java developer, you need to instrument your Java app using the
https://github.com/open-telemetry/opentelemetry-java-instrumentation[OpenTelemetry agent for Java].

By defining the following environment variables, you can customize the OTLP endpoint so that the OpenTelemetry agent communicates with
APM Server.

[source,bash]
----
export OTEL_RESOURCE_ATTRIBUTES=service.name=checkoutService,service.version=1.1,deployment.environment=production
export OTEL_EXPORTER_OTLP_ENDPOINT=https://apm_server_url:8200
export OTEL_EXPORTER_OTLP_HEADERS="authorization=Bearer apm_secret_token"
java -javaagent:/path/to/opentelemetry-javaagent-all.jar \
     -classpath lib/*:classes/ \
     com.mycompany.checkout.CheckoutServiceServer
----

|===

| `OTEL_RESOURCE_ATTRIBUTES` | The service name to identify your application.

| `OTEL_EXPORTER_OTLP_ENDPOINT` | APM Server URL. The host and port that APM Server listens for events on.

| `OTEL_EXPORTER_OTLP_HEADERS` | Authorization header that includes the Elastic APM Secret token or API key: `"authorization=ApiKey api_key"`.

For information on how to format an API key, see our {apm-server-ref-v}/api-key.html[API key] docs.

Please note the required space between `Bearer` and `apm_secret_token`, and `APIKey` and `api_key`.

| `OTEL_EXPORTER_OTLP_CERTIFICATE` | Certificate for TLS credentials of the gRPC client. (optional)

|===

You are now ready to collect <<open-telemetry-elastic-traces-metrics,traces and metrics>>, <<open-telemetry-elastic-verify,verify metrics>>,
and <<open-telemetry-elastic-kibana,visualize metrics>> in {kib}.

IMPORTANT: If collecting metrics, please note that the https://www.javadoc.io/doc/io.opentelemetry/opentelemetry-api/latest/io/opentelemetry/api/metrics/DoubleValueRecorder.html[`DoubleValueRecorder`]
and https://www.javadoc.io/doc/io.opentelemetry/opentelemetry-api/latest/io/opentelemetry/api/metrics/LongValueObserver.html[`LongValueRecorder`] metrics are not yet supported.

[[open-telemetry-elastic-exporter]]
==== Elastic exporter on the OpenTelemetry collector

We have extended the "contrib" OpenTelemetry collector by
adding an Elastic exporter so that you can drop this integration into your current OpenTelemetry setup.

The architecture consists of three main components.

image::images/open-telemetry-exporter-arch.png[OpenTelemetry Elastic exporter architecture diagram]

|===

| *Agents* | The OpenTelemetry agents instrument the applications and export the telemetry data to the OpenTelemetry collector.

| *OpenTelemetry collector* | The https://opentelemetry.io/docs/collector/configuration/#receivers[receiver]
collects the telemetry data from the OpenTelemetry agent, and then the https://opentelemetry.io/docs/collector/configuration/#processors[processor]
defines optional transformations on the data before it's exported using the Elastic exporter.

| *Elastic exporter* | The exporter translates the OpenTelemetry data collected from your services, applications, and infrastructure to Elastic's protocol.
The data includes trace data and metrics data. By extending the OpenTelemetry collector, no changes are needed in your instrumented services to begin using the {stack}.

|===

[float]
[[open-telemetry-collector-config]]
===== Download and configure the collector

OpenTelemetry Collectors can be run as agents or as standalone collectors.
They can be deployed as often as necessary and scaled up or out. Deployment planning resources are available in
OpenTelemetry's {ot-collector}[Getting Started] documentation and {ot-scaling}[Collector Performance] research.

You can download the latest release of the collector from the {ot-contrib}/releases[GitHub releases page].
The Elastic exporter lives in the {ot-contrib}[`opentelemetry-collector-contrib` repository].

Docker images are available on {ot-dockerhub}[dockerhub]:

[source,bash]
----
docker pull otel/opentelemetry-collector-contrib
----

To configure the collector, create a `yaml` configuration file.

This example configuration file accepts input from an OpenTelemetry Agent, processes the data, and sends it to an {ess} instance.

[source,yml]
----
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 'localhost:4317'
    hostmetrics: <1>
      collection_interval: 1m
      scrapers:
        load:
        memory:

  processors:
    batch: null

  exporters:
    elastic:
      apm_server_url: 'https://elasticapm.example.com' <2>
      secret_token: 'APM_SERVER_SECRET_TOKEN'

  service:
    pipelines:
      metrics:
        receivers:
          - otlp
          - hostmetrics
        exporters:
          - elastic <3>
      traces:
        receivers:
          - otlp
        processors:
          - batch
        exporters:
          - elastic <4>
----
<1> The `hostmetrics` receiver must be defined to generate metrics about the host system scraped from various sources.
<2> At a minimum, you must define the URL of the APM Server instance you are sending data to. For additional configurations,
like specifying an API key, secret token, or TLS settings, see the Elastic exporter <<open-telemetry-elastic-config,configuration options>>.
<3> To translate metrics, you must define the Elastic exporter in `service.pipelines.metrics.exporters`.
<4> To translate trace data, you must define the Elastic exporter in `service.pipelines.traces.exporters`.

Once a `receiver`, `processor`, and `exporter` are defined, you can configure {ot-pipelines}[`pipelines`] in your configuration's `services` section.
The `traces` and `metrics` pipelines represent the path of trace data and metrics through your collector and bring all three of these components together.
You can also enable {ot-extension}[`extensions`] for tasks like monitoring the health of the collector.

TIP: We recommend using {metricbeat-ref}/metricbeat-overview.html[{metricbeat}] to get a mature collector with more integrations
and integrated visualizations to collect infrastructure metrics.

[float]
[[open-telemetry-elastic-config]]
===== Elastic exporter configuration options

|===

| `apm_server_url` | Elastic APM Server URL. (required).

| `api_key` | Credential for {apm-server-ref-v}/api-key.html[API key authorization]. Must also be enabled in Elastic APM Server. (optional)

| `secret_token` | Credential for {apm-server-ref-v}/secret-token.html[secret token authorization]. Must also be enabled in Elastic APM Server. (optional)

| `ca_file` | Root Certificate Authority (CA) certificate for verifying the server's identity if TLS is enabled. (optional)

| `cert_file` | Client TLS certificate. (optional)

| `key_file` | Client TLS key. (optional)

| `insecure` | Disable verification of the server's identity if TLS is enabled. (optional)

|===

[float]
[[instrument-apps-collector]]
===== Instrument applications

To export traces and metrics to the OpenTelemetry Collector, ensure that you have instrumented your services and applications
with the OpenTelemetry API, SDK, or both. For example, if you are a Java developer, you need to instrument your Java app using the
https://github.com/open-telemetry/opentelemetry-java-instrumentation[OpenTelemetry agent for Java].

By defining the following environment variables, you can customize the OTLP endpoint the agent will use to communicate with
APM Server.

[source,bash]
----
export OTEL_RESOURCE_ATTRIBUTES=service.name=frontend,service.version=1.1,deployment.environment=staging
export OTEL_EXPORTER_OTLP_ENDPOINT=https://apm_server_url:8200
java -javaagent:/path/to/opentelemetry-javaagent-all.jar \
     -jar target/frontend-1.1.jar
----

|===

| `OTEL_RESOURCE_ATTRIBUTES` | The service name to identify your application.

| `OTEL_EXPORTER_OTLP_ENDPOINT` | APM Server URL. The host and port that APM Server listens for events on.

|===

You are now ready to collect <<open-telemetry-elastic-traces-metrics,traces and metrics>>, <<open-telemetry-elastic-verify,verify metrics>>,
and <<open-telemetry-elastic-kibana,visualize metrics>> in {kib}.

[[open-telemetry-elastic-traces-metrics]]
==== Collect traces and metrics

You're now ready to export traces and metrics from your services and applications.
Here's an example of how to capture business metrics from a Java application.

[source,java]
----
// initialize metric
Meter meter = GlobalMetricsProvider.getMeter("my-frontend");
DoubleCounter orderValueCounter = meter.doubleCounterBuilder("order_value").build();

public void createOrder(HttpServletRequest request) {

   // create order in the database
   ...
   // increment business metrics for monitoring
   orderValueCounter.add(orderPrice);
}
----

See the https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/api.md[Open Telemetry Metrics API]
for more information.

[[open-telemetry-elastic-verify]]
==== Verify OpenTelemetry metrics data

Use *Discover* to validate that metrics are successfully reported to {kib}.

. Launch {kib}:
+
--
include::../tab-widgets/open-kibana-widget.asciidoc[]
--

. Open the main menu, then click *Discover*.
. Select `apm-*` as your index pattern.
. Filter the data to only show documents with metrics: `processor.name :"metric"`
. Narrow your search with a known OpenTelemetry field. For example, if you have an `order_value` field, add `order_value: *` to your search to return
only OpenTelemetry metrics documents.

[[open-telemetry-elastic-kibana]]
==== Visualize in {kib}

TSVB within {kib} is the recommended visualization for OpenTelemetry metrics. TSVB is a time series data visualizer that allows you to use the
{es} aggregation framework's full power. With TSVB, you can combine an infinite number of aggregations to display complex data.

In this example eCommerce OpenTelemetry dashboard, there are four visualizations: sales, order count, product cache, and system load. The dashboard provides us with business
KPI metrics, along with performance-related metrics.

[role="screenshot"]
image::images/ecommerce-dashboard.png[OpenTelemetry visualizations]

Let's look at how this dashboard was created, specifically the Sales USD and System load visualizations.

. Open the main menu, then click *Dashboard*.
. Click *Create dashboard*.
. Click *Save*, enter the name of your dashboard, and then click *Save* again.
. Letâ€™s add a Sales USD visualization. Click *Edit*.
. Click *Create new* and then select *TSVB*.
. For the label name, enter Sales USD, and then select the following:
+
* Aggregation: `Positive Rate`.
* Field: `order_sum`.
* Scale: `auto`.
* Group by: `Everything`
. Click *Save*, enter Sales USD as the visualization name, and then click *Save and return*.
. Now let's create a visualization of load averages on the system. Click *Create new*.
. Select *TSVB*.
. Select the following:
+
* Aggregation: `Average`.
* Field: `system.cpu.load_average.1m`.
* Group by: `Terms`.
* By: `host.ip`.
* Top: `10`.
* Order by: `Doc Count (default)`.
* Direction: `Descending`.
. Click *Save*, enter System load per host IP as the visualization name, and then click *Save and return*.
+
Both visualizations are now displayed on your custom dashboard.

IMPORTANT: By default, Discover shows data for the last 15 minutes. If you have a time-based index
and no data displays, you might need to increase the time range.

[[open-telemetry-aws-lambda-elastic]]
==== AWS Lambda Support

AWS Lambda functions can be instrumented with OpenTelemetry and monitored with Elastic Observability.

To get started, follow the official AWS Distro for OpenTelemetry Lambda https://aws-otel.github.io/docs/getting-started/lambda[getting started documentation] and configure the OpenTelemetry Collector to output traces and metrics to your Elastic cluster.

[[open-telemetry-aws-lambda-elastic-java]]
==== Instrumenting AWS Lambda Java functions

NOTE: For a better startup time, we recommend using SDK-based instrumentation, i.e. manual instrumentation of the code, rather than auto instrumentation.

To instrument AWS Lambda Java functions, follow the official https://aws-otel.github.io/docs/getting-started/lambda/lambda-java[AWS Distro for OpenTelemetry Lambda Support For Java].

Noteworthy configuration elements:

* AWS Lambda Java functions should extend `com.amazonaws.services.lambda.runtime.RequestHandler`,
+
[source,java]
----
public class ExampleRequestHandler implements RequestHandler<APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent> {
    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent event, Context context) {
        // add your code ...
    }
}
----

* When using SDK-based instrumentation, frameworks you want to gain visibility of should be manually instrumented
** The below example instruments https://square.github.io/okhttp/4.x/okhttp/okhttp3/-ok-http-client/[OkHttpClient] with the OpenTelemetry instrument https://search.maven.org/artifact/io.opentelemetry.instrumentation/opentelemetry-okhttp-3.0/1.3.1-alpha/jar[io.opentelemetry.instrumentation:opentelemetry-okhttp-3.0:1.3.1-alpha]
  +
[source,java]
----
import io.opentelemetry.instrumentation.okhttp.v3_0.OkHttpTracing;

OkHttpClient httpClient = new OkHttpClient.Builder()
        .addInterceptor(OkHttpTracing.create(GlobalOpenTelemetry.get()).newInterceptor())
        .build();
----

* The configuration of the OpenTelemetry Collector, with the definition of the Elastic Observability endpoint, can be added to the root directory of the Lambda binaries (e.g. defined in `src/main/resources/opentelemetry-collector.yaml`)
+
[source,yaml]
----
# Copy opentelemetry-collector.yaml in the root directory of the lambda function
# Set an environment variable 'OPENTELEMETRY_COLLECTOR_CONFIG_FILE' to '/var/task/opentelemetry-collector.yaml'
receivers:
  otlp:
    protocols:
      http:
      grpc:

exporters:
  logging:
    loglevel: debug
  otlp/elastic:
    # Elastic APM server https endpoint without the "https://" prefix
    endpoint: "${ELASTIC_OTLP_ENDPOINT}" <1>
    headers:
      # Elastic APM Server secret token
      Authorization: "Bearer ${ELASTIC_OTLP_TOKEN}" <1>

service:
  pipelines:
    traces:
      receivers: [otlp]
      exporters: [logging, otlp/elastic]
    metrics:
      receivers: [otlp]
      exporters: [logging, otlp/elastic]
----
<1> Environment-specific configuration parameters can be conveniently passed in as environment variables: `ELASTIC_OTLP_ENDPOINT` and `ELASTIC_OTLP_TOKEN`

* Configure the AWS Lambda Java function with:
** https://docs.aws.amazon.com/lambda/latest/dg/API_Layer.html[Function
layer]: The latest https://aws-otel.github.io/docs/getting-started/lambda/lambda-java[AWS
Lambda layer for OpenTelemetry] (e.g. `arn:aws:lambda:eu-west-1:901920570463:layer:aws-otel-java-wrapper-ver-1-2-0:1`)
** https://docs.aws.amazon.com/lambda/latest/dg/API_TracingConfig.html[TracingConfig / Mode] set to `PassTrough`
** https://docs.aws.amazon.com/lambda/latest/dg/API_FunctionConfiguration.html[FunctionConfiguration / Timeout] set to more than 10 seconds to support the longer cold start inherent to the Lambda Java Runtime
** Export the environment variables:
*** `AWS_LAMBDA_EXEC_WRAPPER="/opt/otel-proxy-handler"` for wrapping handlers proxied through the API Gateway (see https://aws-otel.github.io/docs/getting-started/lambda/lambda-java#enable-auto-instrumentation-for-your-lambda-function[here])
*** `OTEL_PROPAGATORS="tracecontext, baggage"` to override the default setting that also enables X-Ray headers causing interferences between OpenTelemetry and X-Ray
*** `OPENTELEMETRY_COLLECTOR_CONFIG_FILE="/var/task/opentelemetry-collector.yaml"` to specify the path to your OpenTelemetry Collector configuration

[[open-telemetry-aws-lambda-elastic-java-terraform]]
==== Instrumenting AWS Lambda Java functions with Terraform

We recommend using an infrastructure as code solution like Terraform or Ansible to manage the configuration of your AWS Lambda functions.

Here is an example of AWS Lambda Java function managed with Terraform and the https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/lambda_function[AWS Provider / Lambda Functions]:

* Sample Terraform code: https://github.com/cyrille-leclerc/my-serverless-shopping-cart/tree/main/checkout-function/deploy
* Note that the Terraform code to manage the HTTP API Gateway (https://github.com/cyrille-leclerc/my-serverless-shopping-cart/tree/main/utils/terraform/api-gateway-proxy[here]) is copied from the official OpenTelemetry Lambda sample https://github.com/open-telemetry/opentelemetry-lambda/tree/e72467a085a2a6e57af133032f85ac5b8bbbb8d1/utils[here]

// Make tab-widgets work
include::../tab-widgets/code.asciidoc[]
